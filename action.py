import pandas as pd
import re
import nltk
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
from sklearn.utils import resample
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

import sys
sys.stdout.reconfigure(encoding='utf-8')



# NLTK Stopwords ‡¶è‡¶¨‡¶Ç Lemmatizer ‡¶°‡¶æ‡¶â‡¶®‡¶≤‡ßã‡¶°
nltk.download('stopwords')
nltk.download('wordnet')
stop_words = set(stopwords.words('english'))
lemmatizer = WordNetLemmatizer()

# ‚úÖ 1. CSV ‡¶´‡¶æ‡¶á‡¶≤ ‡¶≤‡ßã‡¶° ‡¶ï‡¶∞‡¶æ
df = pd.read_csv("sms_data.csv")

# ‚úÖ 2. ‡¶°‡¶æ‡¶ü‡¶æ ‡¶¨‡ßç‡¶Ø‡¶æ‡¶≤‡¶æ‡¶®‡ßç‡¶∏ ‡¶ï‡¶∞‡¶æ (Spam & Important ‡¶∏‡¶Æ‡¶æ‡¶® ‡¶ï‡¶∞‡¶æ)
df_spam = df[df["Label"] == "Spam"]
df_important = df[df["Label"] == "Important"]
df_spam_upsampled = resample(df_spam, replace=True, n_samples=len(df_important), random_state=42)
df_balanced = pd.concat([df_important, df_spam_upsampled])

# ‚úÖ 3. ‡¶â‡¶®‡ßç‡¶®‡¶§ ‡¶ü‡ßá‡¶ï‡ßç‡¶∏‡¶ü ‡¶ï‡ßç‡¶≤‡¶ø‡¶®‡¶ø‡¶Ç ‡¶´‡¶æ‡¶Ç‡¶∂‡¶®
def preprocess_text(text):
    text = text.lower()
    text = re.sub(r'\W', ' ', text)
    text = re.sub(r'\s+', ' ', text).strip()
    words = text.split()
    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]
    return ' '.join(words)

df_balanced["Cleaned_Text"] = df_balanced["SMS Text"].apply(preprocess_text)

# ‚úÖ 4. ‡¶ü‡ßá‡¶ï‡ßç‡¶∏‡¶ü ‡¶≠‡ßá‡¶ï‡ßç‡¶ü‡¶∞‡¶æ‡¶á‡¶ú‡ßá‡¶∂‡¶® (TF-IDF)
vectorizer = TfidfVectorizer()
X_balanced = vectorizer.fit_transform(df_balanced["Cleaned_Text"])
y_balanced = df_balanced["Label"]

# ‚úÖ 5. ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶ü‡ßç‡¶∞‡ßá‡¶®‡¶ø‡¶Ç
X_train, X_test, y_train, y_test = train_test_split(X_balanced, y_balanced, test_size=0.2, random_state=42)
model = MultinomialNB()
model.fit(X_train, y_train)

# ‚úÖ 6. ‡¶è‡¶ï‡ßÅ‡¶∞‡ßá‡¶∏‡¶ø ‡¶ö‡ßá‡¶ï ‡¶ï‡¶∞‡¶æ
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print("‚úÖ Model Training Successful!")
print("üìä Model Accuracy:", accuracy)

# ‚úÖ 7. ‡¶ó‡ßÅ‡¶∞‡ßÅ‡¶§‡ßç‡¶¨‡¶™‡ßÇ‡¶∞‡ßç‡¶£ ‡¶ï‡¶ø‡¶ì‡ßü‡¶æ‡¶∞‡ßç‡¶° ‡¶ö‡ßá‡¶ï ‡¶ï‡¶∞‡ßá Prediction ‡¶ï‡¶∞‡¶æ
IMPORTANT_KEYWORDS = ["otp", "bank", "transaction", "payment", "account", "salary", "bill", "invoice", "password","‡¶ü‡ßç‡¶∞‡¶æ‡¶®‡¶ú‡ßç‡¶Ø‡¶æ‡¶ï‡¶∂‡¶®"]

def check_sms(text):
    if any(keyword in text.lower() for keyword in IMPORTANT_KEYWORDS):  # ‚úÖ ‡¶ó‡ßÅ‡¶∞‡ßÅ‡¶§‡ßç‡¶¨‡¶™‡ßÇ‡¶∞‡ßç‡¶£ ‡¶ï‡¶ø‡¶ì‡ßü‡¶æ‡¶∞‡ßç‡¶° ‡¶•‡¶æ‡¶ï‡¶≤‡ßá Important
        return "Important"
    text_cleaned = preprocess_text(text)
    text_vectorized = vectorizer.transform([text_cleaned])
    prediction = model.predict(text_vectorized)
    return prediction[0]

sms_input = input("Enter an SMS: ")
result = check_sms(sms_input)
print("Prediction:", result)

